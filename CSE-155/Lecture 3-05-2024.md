s# Order of Control
- Relationship between property sensed and order of control
	- The order of control is the sequence of how you input controls for a given computer system
- Property sensed
	- Things that the input device can detect
		- (Absolute) Position (touchscreen)
		- Displacement (mouse, joystick, analogue)
		- Force (different types of joysticks, such as with load sensors, or some touch screens)
- Order of control (property of display controlled)
	- Things that the input device can manipulate in the virtual world
		- Things we normally do in computer systems
		- Position (of cursor/object)
		- Velocity (of cursor/object)
- Example: joysticks, as a controller
	- Isotonic joysticks sense displacement of the stick
		- e.g., what most people think about joysticks
	- Isometric joysticks sense force applied to stick
		- e.g., trackpoint or the laptop dot mouse thing
			- hi cube
	- Mapping:
		- Optimal mappings:
			- Isotonic joysticks: position control
			- Isometric joystick: velocity control
				- Not very natural but most efficient
		- Isotonic devices (e.g., mouse) appropriate for position control
		- Elastic or isometric devices (e.g., joystick) are the most appropriate for rate (velocity) control
			- also more precise
	- Mixed control
		- Increasing the input space of a trackpad by combining position and rate control
		- E.g., different types of inputs to a device allow you to extend the range
		- (RubberEdge, reducing clutching by combining position and rate control with elastic feedback)
			- Allows both position and velocity
			- Applies on top of an existing trackpad, implying momentum and inertia 
			- Reduces clutching (e.g., picking up your finger from the trackpad and putting it down)
			- Increases issue of overshooting
				- But fixes an issue with dynamic velocity

## Natural and Learned Relationships
- With natural relationships, users don't have to learn operation of a control device
- Interactions should be congruent - the input should be the same result as the output (push up, result is up, not forward)
- You can make something blend into a natural environment
	- If you don't have to think about it, it's usually natural
	- The relationships are spatially congruent
	- Such interfaces are essentially invisible, unless users want to learn complex interactions
	- Often referred to as a natural user interface (NUI)
- With learned relationships, users learn the operations of a control device:
	- Require spatial transformation
		- 1-1 is congruent, otherwise it isn't
			- E.g., a dial doesn't map to a linear relationship like a volume control
			- Learned because the rotation direction isn't obvious to usage
	- Learned relationships seem natural if they lead to a population stereotype or cultural standard
		- E.g., a light switch can be defined off in a country and on in a different one
		- Or scrolling on a trackpad: natural scrolling vs normal scrolling (or australian scrolling, depending on who you're asking)
		- You know it so well and it's expected in a region, but not obvious to everyone, therefore it's learned
		- Media gestures are also culturally reliant when it comes to interacting with a system
		- A lot of interaction designers do an illustration study, to ask them to perform an interaction and what they come up with
			- Many different, many common, but there are also many unique
				- Reliant on age, gender, culture, etc.
					- Some are "universal" to some extent
- In other words, something might be "natural" only because everyone knows - but it's not really.
## Mental Models
- We've talked about this before
	- A psychological representation of a real, hypothetical, or imaginary situation
		- You know what something vaguely is because it fits in a bucket of knowledge - allowing you to infer something new
	- New software should look similar to old software, because it should be familiar to use
	- You make small-scale models and combine them to make a more complex model, to understand a full workflow
		- Each person has different mental models, and it alters how they interact with a system
- How to build one?
	- Interaction: you try something, you get a response - you learn it
	- Explanation: someone tells you how something works, usually from their interactions - not personal, but you can memorize it and see if it's true
		- Based on someone else's experience - you kinda know but like most things people say, you don't fully understand by default
- Two types of mental models
	- Functional: knowing *what* to do but not *why* 
		- e.g., closing the browser before shutting down the computer
		- You know something can be done, and you know how to use it - you don't know how to fix if something goes wrong, and even then most fixes you know are surface level (e.g., turn it off and turn it on again)
	- Structural: understanding the components and their relationships (both *what* and *why*)
		- Allows us to actually solve problems
		- You know how everything knows in the background, so you know how to resolve issues
		- Not all UX designers have structural knowledge - they might not be able to explain how a system works, but they can *suggest* solutions - not exact and even worse, might not be the best solution
- A mental model is based on **belief**, not **facts**
	- What a user knows or *thinks they know* about a system
		- Could be even wrong!
		- How they predict the system works based on existing mental models, which influences their future actions
	- Key goal for designers: the UI communicate a system's basic nature well enough that users form reasonably accurate mental models
		- Simple to gain functional knowledge that is *accurate*
		- Good relationship between how you see your software working and how they see it
		- Human diversity changes everything
- Individual users have their own mental models - different users have different mental models, and they all might have different ideas of how to use software
	- The gap between designers' and users' models is a usability dilema
		- Designers know everything already... of course the user doesn't understand.
	- Training helps, but it's slow
	- Documentation also helps, but also slow
		- Why not get user feedback for better UI/UX design?
	- Main goal is to iterate on a design until people get it better and faster
		- Note that some people might think of different ways to do something - allow both ways to reach the same answer, but encourage them to try the faster way
- Conceptual Model: A high-level model that works for the user: what they want them to have
	- How to interpret the system: a guide
- System Model: a low-level model that shows how a system functions depending on user input
	- Also known as functional modeling and architectural modeling
	- Uses UML or other modeling languages to show how a system is functioning

![[Pasted image 20240305141557.png]]
Effectively a pathway from design to development to usage

## Metaphors
- We've also talked about these - exploiting things that people know to increase skill transfer and helping understanding a model
- But don't take it literally - e.g., a pencil tool doesn't have to act as a pencil, but it can represent things like fixed-sized drawing lines or even just an indicator to edit something
	- Mail icons for E-Mail, clock direction for inputting numbers into a system, etc.
	- Also some people dont' know things...
		- People can't read analog clocks nowdays so that notation might be hard to understand from the start
		- Or numpad notation for people playing fighting games when they're using a controller
- Physical watches need to be durable to tell time - cannot break easily for blind people
- Talking watches are loud, and sometimes you don't want to annoy people
- Braille watch? expensive
	- also not many people can read braille
	- Human factors