# Descriptive Models
- "By its very nature, a model is a simplification of reality" - I. Scott MacKenzie
	- Mathematical models, physical models, etc. to help us understand
		- Predictive models (data)
			- Split between a human and a system - you can predict how a system works, how the human works, or both (i.e., interaction)
	- Analogies and metaphors work too - all on a continuum
		- Descriptive models (what it is)
	- Not all models are one or the other - often are in the middle

## Descriptive & Predictive Modeling
- A model is useful only if it helps in designing, evaluating, or understanding complex systems
- A range between Concept Abstractions and Math: most are in between, but there exist pure ones

### Descriptive Models
- Example 1: Buxton's 3-state model
	- A simple expression of the operation of computer pointing devices in terms of state transitions
	- Relationship between pointing devices and the interaction techniques they afford
	- States are the possible modes, and there are actions to move between states (e.g., moving a mouse, clicking a button, dragging)
		- E.g., a mouse has three states:
			- not tracking (e.g., mouse off table, by picking it up)
			- tracking (e.g., mouse on table, after putting it down)
			- dragging (button down, from tracking)
		- New input technologies allow more or less states, e.g, touch screen (two states: touching, and not touching)
			- More modes of how one would switch between states
	- Can you convert from a descriptive model to a predictive model?
		- How? Let's assume you have multiple states.
			- We want to know how long it'd take for someone to click a button.
				- We need to know the probability of being in one state or another ($p_r$)
					- note: subscripts represent a state, arbitrarily picking $r$
				- We need to know how long the action would take to move from one state to another ($t_r$)
				- Multiply these two for a total time
				- Add for all possible states to get the average time it would take to know how long it'd take for them to click a button

### Scale of Human Action
![[Pasted image 20240123134816.png]]
We have different time scales for the societal impact of technology, and how they'd correspond to 
- Exponential growth due to computing, exploiting them to save time
- Could be extended it to historical and even evolutionary bands
	- Fuckin boomers
- Allows us to predict the length of actions in different scales

### Human Factors Model

Sensors are mostly your five senses, but it's possible more could be added (artificially) or even removed (oops)
- Note that sensors could also been mutated, e.g., being color blind
	- me
- Neural activation upon sensor
	- Responders are usually your limbs/hands, but also voice and eyes
		- Or again, you can artificially add them too (neuralink!)
		- Or even more, a sensor could be a responder too
			- Eye tracking: you see and act
			- Your brain doesn't have to trigger your limbs if it tells the computer (brain activity)
	- Computer also can have more sensors as controls
		- Maybe temperature or pressure

|  | Human | Interface | Computer |  |
| ---- | ---- | ---- | ---- | ---- |
| the brain | <- Sensors | <- | <- Displays | Machine State |
|  | Responders -> | -> | Controls -> |  |
## Human Vision
- We receive 80% of our information via the eye
- But the fovea is the where the sharpest part of the image is, and it's 1% of the retina (very smol)
	- This is important for details, such as reading or watching TV
		- You focus on this, like the width of one's thumb at arm's length
	- So, what's the rest? Peripheral vision, and you don't need *all* of it
- OK, so what's the point?
	- I don't want to move my eyes! Everything related should be grouped together - I shouldn't be scrolling my eyes to see the content.
		- Also, font size needs to be sufficient but not overwhelm other content, but also not be too small that I need a microscope to read it
	- It also helps the user understand what content is related to what
- Neural processing associated with the fovea image engages about 50% of the visual cortex in the brain
### Visual Stimulus
- Physical properties of light
	- We don't work in numbers...
	- Frequency and Intensity (luminance)
		- Subjective: we can perspective light differently, even if the lux/brightness is the same
	- Hue/Saturation
		- OK, it's this color... oops i'm colorblind
- Warm and cool colors
	- Warm colors are associated with daylight or sunset
	- Cool colors are associated with a gray or overcast day
		- Wtf is the most "warm" or "cool" color: researchers don't know the answer!
			- we're paying them too much for this shit
	- Warm colors are "active", cool colors are "calm" (allegedly)
		- mf said warm colors are "arousing"
	- Colors that are dangerous as well?
		- Lions as an example, like a survival mode
			- Fight and flight, possible usage for errors
		- Increases speed and force, decreases patience with these warmer colors
	- You can use a mix of warm and cool colors to represent creativity or how much "action" it represents
	- Colors can also be used to pop out details (e.g., a special marker on a map), but cannot be relied on (again, color blind people)
		- Also, colors might not be usable since they could be new to your computer
		- Redundant methods (e.g., text, text style/bold, icons, size) could be used to complement the color
	- Color coding can also be used to assign specific colors to specific actions (e.g., red: danger, deletion, green: creation, addition)
		- Again, warning for color blindness! (red-green)
- Types of feedback:
	- Haptic (feeling)
		- Vibration, force, texture
	- Graphical (seeing)
		- Images, colors, fonts, type, animation
	- Auditory (hearing)
		- Sound, audio, sfx, alarms, pitch/intensity, delay
	- Multi-modal (multiple)
		- you should know this
- Colorblindness
	- Females: 0.5%
	- Male: 8.0% (losers)
- We perceive about 150 hues, 7 million colors, but can name only a few
	- on average, 12 names
- Red/green colorblindness is the biggest
- Animation patterns can assist with color coding, since it can be compatible with both color blind and motion assisted